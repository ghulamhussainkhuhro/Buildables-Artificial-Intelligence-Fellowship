{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6d61453-bb58-41c6-a19b-7f545035ab66",
   "metadata": {},
   "source": [
    "#  Using Groq API in Python (Jupyter Notebook Demo)\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Set up environment variables for the **Groq API**.\n",
    "2. Load our `.env` file safely using `python-dotenv`.\n",
    "3. Send a request to the **Groq client**.\n",
    "4. Print the model's response.\n",
    "\n",
    "This will help us see how to make real-time API calls step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266a2d3f-ba5b-4971-aad8-793d70cfc599",
   "metadata": {},
   "source": [
    "##  Step 1 â€” Install Dependencies\n",
    "We need to install the following:\n",
    "- **groq** â†’ Official Groq Python client.\n",
    "- **python-dotenv** â†’ To load `.env` file for the API key.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399e4132-fd6f-42e6-8036-ab734c019a8e",
   "metadata": {},
   "source": [
    "!pip install groq python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5349a9-b361-43a6-be86-16f922ee1878",
   "metadata": {},
   "source": [
    "##  Step 2 â€” Set Up `.env` File\n",
    "Inside your project folder, create a file named `.env` with the following content:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1ca00-ccf2-497f-b398-7f859a65d3b8",
   "metadata": {},
   "source": [
    "\n",
    " Make sure **never to hardcode your API key** in the notebook â€” only load it from `.env`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10107932-4835-4bf2-8c13-592f41834729",
   "metadata": {},
   "source": [
    "##  Step 3 â€” Import Libraries and Load API Key\n",
    "We will import:\n",
    "- `os` â†’ for environment variables\n",
    "- `Groq` â†’ Groq API client\n",
    "- `load_dotenv` â†’ load API key from `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "989d130a-4798-495c-a491-bb941d36d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file (adjust path if needed)\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "# Initialize client with API key\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bade7f3-da3c-456d-877f-b6c61bff6c5e",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Step 4 â€” Make a Chat Completion Request\n",
    "We will send a simple prompt:\n",
    "> \"Explain the importance of fast language models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aebff5f-7650-40ea-b38d-a6b0b2445846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's technology landscape, and their importance can be understood from several perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process and analyze vast amounts of text data quickly, making them ideal for applications where speed is essential, such as:\n",
      "\t* Real-time language translation\n",
      "\t* Sentiment analysis in social media monitoring\n",
      "\t* Chatbots and virtual assistants\n",
      "\t* Text summarization and content generation\n",
      "2. **Improved User Experience**: Fast language models enable responsive and interactive systems, which leads to a better user experience. For instance:\n",
      "\t* Quick response times in chatbots and voice assistants\n",
      "\t* Fast autocomplete and suggestions in search bars and text editors\n",
      "\t* Efficient language translation and subtitles in video streaming services\n",
      "3. **Scalability and Cost-Effectiveness**: Fast language models can handle large volumes of data and user requests, making them scalable and cost-effective:\n",
      "\t* Reduced computational resources and energy consumption\n",
      "\t* Lower latency and improved system responsiveness\n",
      "\t* Increased throughput and capacity to handle multiple users and requests\n",
      "4. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage by:\n",
      "\t* Quickly analyzing and responding to customer feedback and concerns\n",
      "\t* Developing more accurate and efficient language-based systems\n",
      "\t* Enhancing their brand reputation and user engagement\n",
      "5. **Advancements in NLP Research**: Fast language models accelerate the development of new natural language processing (NLP) techniques and applications, such as:\n",
      "\t* Multimodal learning (e.g., text, images, and audio)\n",
      "\t* Low-resource language support\n",
      "\t* Transfer learning and few-shot learning\n",
      "6. **Real-World Applications**: Fast language models have numerous real-world applications, including:\n",
      "\t* Language translation and localization\n",
      "\t* Text classification and sentiment analysis\n",
      "\t* Named entity recognition and information extraction\n",
      "\t* Dialogue systems and conversational AI\n",
      "7. **Ethical and Social Implications**: Fast language models can also have significant social and ethical implications, such as:\n",
      "\t* Enabling more accessible and inclusive language technologies\n",
      "\t* Facilitating communication across languages and cultures\n",
      "\t* Raising concerns about bias, fairness, and accountability in AI systems\n",
      "\n",
      "In summary, fast language models are essential for developing efficient, scalable, and responsive language-based systems, which can lead to improved user experiences, competitive advantages, and advancements in NLP research. Their importance extends to various real-world applications and has significant social and ethical implications.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"},\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d0ef3-76e9-4f69-ae67-c46ad8cec9a9",
   "metadata": {},
   "source": [
    "##  Step 5 â€” Experiment with Different Prompts\n",
    "Try changing the user input and re-run the code to test:\n",
    "- Creative writing\n",
    "- Summarization\n",
    "- Explanation of concepts\n",
    "\n",
    "This way you can interact with the model just like in a real-time chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab2ea0-f3d7-4063-938d-ddbee6e97201",
   "metadata": {},
   "source": [
    "## Step 6 â€” Crack a Joke\n",
    "Now let's ask the model to tell us a joke!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641321b0-2c74-4417-81ec-30d787778b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs.\n"
     ]
    }
   ],
   "source": [
    "joke_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a funny programming joke\"},\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(joke_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd35cb-81ff-4e80-95b7-ef66088d6e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
